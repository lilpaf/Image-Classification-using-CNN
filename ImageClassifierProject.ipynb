{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1cdac66-2566-4f51-a567-391735543e44",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "343d6566-6f7a-425f-9344-d1ade00f95e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms, models\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed07a68-bd03-4136-bd5a-b61dc15816ee",
   "metadata": {},
   "source": [
    "# Checking for device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7fa3d17-f9bc-41da-b872-4cb9307356ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e70b0e-c00e-4180-9f9b-6ff656be70ae",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5994470f-d897-4c49-af05-b17f4665e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40bb2353-0a14-4e35-a94e-9612fdd0c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='./seg_train/seg_train'\n",
    "test_path='./seg_test/seg_test'\n",
    "\n",
    "train_loader= DataLoader(datasets.ImageFolder(train_path,transform=data_transformer), batch_size=64, shuffle=True)\n",
    "test_loader= DataLoader(datasets.ImageFolder(test_path,transform=data_transformer), batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a06010a-1b95-45f6-8bbe-6a2acc2fdc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n"
     ]
    }
   ],
   "source": [
    "root = pathlib.Path(train_path)\n",
    "classes = sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200b56b4-c6c1-4c56-8677-69848fbdea9e",
   "metadata": {},
   "source": [
    "# CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14718462-2a9d-4fe9-8ceb-78c8357cc492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        # Output size after convolution filter\n",
    "        # ((w - f + 2P) / s) + 1\n",
    "        \n",
    "        # Inpit shape = (256, 3, 150, 150)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape (256, 12, 150, 150)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        # Shape (256, 12, 150, 150)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # Shape (256, 12, 150, 150)\n",
    "\n",
    "        # Reudce the image size by factor of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # Shape (256, 12, 75, 75)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape (256, 20, 75, 75)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Shape (256, 20, 75, 75)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # Shape (256, 32, 75, 75)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        # Shape (256, 32, 75, 75)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # Shape (256, 32, 75, 75)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=75 * 75 * 32, out_features=num_classes)\n",
    "\n",
    "    # Feed forward function \n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "              \n",
    "        output = self.pool(output)\n",
    "              \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "              \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "                \n",
    "        # Above output will be in matrix form, with shape (256,32,75,75)\n",
    "            \n",
    "        output = output.view(-1, 32 * 75 * 75)\n",
    "              \n",
    "        output = self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9c662b8-1587-42fa-857e-650cc1963928",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb73186-8914-473d-8394-fd56c8dc0818",
   "metadata": {},
   "source": [
    "# Model training and saving best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "500e34d7-6bf2-49b5-8c6b-d1f101485e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr = 0.001, weight_decay = 0.0001)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9a75091-f7ac-41c2-be38-612ef2c1a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "647cacc9-9b93-431a-b910-6c775155e9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14034 3000\n"
     ]
    }
   ],
   "source": [
    "# Calculating the size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
    "\n",
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e35ebedf-08d6-4998-b426-4814e2c15008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(6.1917) Train Accuracy: 0.5948411001852644 Test Accuracy: 0.699\n",
      "Epoch: 1 Train Loss: tensor(2.0657) Train Accuracy: 0.7292290152486818 Test Accuracy: 0.6136666666666667\n",
      "Epoch: 2 Train Loss: tensor(1.0190) Train Accuracy: 0.8032635029214764 Test Accuracy: 0.6883333333333334\n",
      "Epoch: 3 Train Loss: tensor(0.5898) Train Accuracy: 0.8525010688328345 Test Accuracy: 0.7606666666666667\n",
      "Epoch: 4 Train Loss: tensor(0.4228) Train Accuracy: 0.8858486532706284 Test Accuracy: 0.738\n",
      "Epoch: 5 Train Loss: tensor(0.2176) Train Accuracy: 0.9335898532136241 Test Accuracy: 0.7576666666666667\n",
      "Epoch: 6 Train Loss: tensor(0.1696) Train Accuracy: 0.9529713552800342 Test Accuracy: 0.767\n",
      "Epoch: 7 Train Loss: tensor(0.1473) Train Accuracy: 0.956890409006698 Test Accuracy: 0.7466666666666667\n",
      "Epoch: 8 Train Loss: tensor(0.1180) Train Accuracy: 0.9641584722816018 Test Accuracy: 0.7353333333333333\n",
      "Epoch: 9 Train Loss: tensor(0.1600) Train Accuracy: 0.9551090209491235 Test Accuracy: 0.7013333333333334\n"
     ]
    }
   ],
   "source": [
    "# Model training and saving best model\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss += loss.cpu().data * images.size(0)\n",
    "        _,prediction = torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy / train_count\n",
    "    train_loss=train_loss / train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        outputs = model(images)\n",
    "        _,prediction = torch.max(outputs.data,1)\n",
    "        test_accuracy += int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy / test_count\n",
    "    \n",
    "    \n",
    "    print(f'Epoch: {str(epoch)} Train Loss: {str(train_loss)} Train Accuracy: {str(train_accuracy)} Test Accuracy: {str(test_accuracy)})\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy\n",
    "    \n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
